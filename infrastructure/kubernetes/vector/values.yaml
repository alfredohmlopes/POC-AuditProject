# Vector Helm Values
# https://helm.vector.dev
role: Aggregator

replicas: 3

customConfig:
  data_dir: "/vector-data-buffer"
  
  sources:
    http_ingest:
      type: "http_server"
      address: "0.0.0.0:8080"
      encoding: "json"
    
    # Kafka consumer from Redpanda for storage pipeline
    kafka_consumer:
      type: "kafka"
      bootstrap_servers: "redpanda.redpanda.svc.cluster.local:9093"
      group_id: "audit-consumer-group"
      topics: ["audit.events.v1"]
      auto_offset_reset: "earliest"
      decoding:
        codec: "json"
      sasl:
        enabled: true
        mechanism: "SCRAM-SHA-256"
        username: "turia-producer"
        password: "changeme_producer123"
    
    internal_metrics:
      type: "internal_metrics"

  transforms:
    validate:
      type: "remap"
      inputs: ["http_ingest"]
      source: |
        assert!(exists(.actor.id), "actor.id is required")
        assert!(exists(.action.name), "action.name is required")
        assert!(exists(.resource.type), "resource.type is required")
        assert!(exists(.resource.id), "resource.id is required")

    enrich:
      type: "remap"
      inputs: ["validate"]
      source: |
        .event_id = uuid_v7()
        .received_at = now()
        .event_date = format_timestamp!(.timestamp || now(), "%Y-%m-%d")
        .processing.vector_node = get_hostname!()
        .action.name = downcase(string!(.action.name))
        .tenant_id = .tenant_id || "default_tenant"
    
    # Prepare events from Kafka for storage
    prepare_storage:
      type: "remap"
      inputs: ["kafka_consumer"]
      source: |
        # Events already enriched from production, ensure event_date for partitioning
        .event_date = .event_date || format_timestamp!(now(), "%Y-%m-%d")

  sinks:
    # Sink to Prometheus Exporter for scraping
    prometheus_exporter:
      type: "prometheus_exporter"
      inputs: ["internal_metrics"]
      address: "0.0.0.0:9090"
    
    # Sink to Redpanda (Kafka) - Production
    redpanda:
      type: "kafka"
      inputs: ["enrich"]
      bootstrap_servers: "redpanda.redpanda.svc.cluster.local:9093"
      topic: "audit.events.v1"
      key_field: "tenant_id"
      compression: "lz4"
      encoding:
        codec: "json"
      batch:
        max_bytes: 1048576 # 1MB
        timeout_secs: 1
      acknowledgements:
        enabled: true
      sasl:
        enabled: true
        mechanism: "SCRAM-SHA-256"
        username: "turia-producer"
        password: "changeme_producer123"
    
    # ClickHouse Sink for Analytics (E3.S2)
    clickhouse:
      type: "clickhouse"
      inputs: ["prepare_storage"]
      endpoint: "http://clickhouse.clickhouse.svc.cluster.local:8123"
      database: "audit"
      table: "events"
      compression: "gzip"
      batch:
        max_events: 10000
        timeout_secs: 5
      request:
        retry_attempts: 3
        retry_initial_backoff_secs: 1
        retry_max_duration_secs: 10
    
    # OpenSearch Sink for Full-Text Search (E3.S3)
    opensearch:
      type: "elasticsearch"
      inputs: ["prepare_storage"]
      endpoints: ["http://opensearch-cluster-master.opensearch.svc.cluster.local:9200"]
      api_version: "v7"
      mode: "bulk"
      bulk:
        index: '{{ "{{" }} .event_date {{ "}}" }}'
        action: "index"
      batch:
        max_events: 5000
        timeout_secs: 5
      request:
        retry_attempts: 3
        retry_initial_backoff_secs: 1
        retry_max_duration_secs: 10
    
    # Debug console
    console_debug:
      type: "console"
      inputs: ["prepare_storage"]
      encoding:
        codec: "json"

persistence:
  enabled: true
  storageClassName: "standard" # or standard-ssd depending on cluster, trying standard first or empty for default
  accessModes:
    - ReadWriteOnce
  size: 1Gi

service:
  enabled: true
  type: ClusterIP
  ports:
    - name: http
      port: 8080
      targetPort: 8080
    - name: http-batch
      port: 8081
      targetPort: 8081
    - name: prom-exporter
      port: 9090
      targetPort: 9090

# Enable PodMonitor or ServiceMonitor if Prometheus Operator installed
serviceMonitor:
  enabled: true
  path: "/metrics"
  port: "prom-exporter"
